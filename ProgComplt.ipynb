{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "colab_type": "code",
        "id": "SI00_01a9JFi",
        "outputId": "dfe2f873-076d-4c8f-b77f-7e0addb6fb25"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:107: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, kernel_size=(4, 4), input_shape=(200, 200,..., activation=\"relu\", padding=\"valid\")`\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "20/20 [==============================] - 3s 152ms/step - loss: 1.0390 - acc: 0.7092 - val_loss: 0.9106 - val_acc: 0.7033\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 3s 147ms/step - loss: 0.8776 - acc: 0.7367 - val_loss: 0.9132 - val_acc: 0.7033\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 3s 142ms/step - loss: 0.8844 - acc: 0.7383 - val_loss: 0.8983 - val_acc: 0.7033\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 3s 146ms/step - loss: 0.8812 - acc: 0.7375 - val_loss: 0.9043 - val_acc: 0.7033\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 0.8803 - acc: 0.7375 - val_loss: 0.9081 - val_acc: 0.7033\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 3s 145ms/step - loss: 0.8704 - acc: 0.7375 - val_loss: 0.9052 - val_acc: 0.7033\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 3s 150ms/step - loss: 0.8847 - acc: 0.7375 - val_loss: 0.9008 - val_acc: 0.7033\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.8710 - acc: 0.7375 - val_loss: 0.9233 - val_acc: 0.7033\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 3s 145ms/step - loss: 0.8769 - acc: 0.7375 - val_loss: 0.8976 - val_acc: 0.7033\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 3s 146ms/step - loss: 0.8836 - acc: 0.7375 - val_loss: 0.9012 - val_acc: 0.7033\n",
            "[0.9012218793233235, 0.703333334128062]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.optimizers import adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#Cargamos los datos de trainLabels.csv\n",
        "#Definiendo las imagenes con la se trabajaran\n",
        "\n",
        "ubic = 'train'\n",
        "arch = os.listdir(ubic)\n",
        "arch.remove(\"trainLabels.csv\") #Eliminamos trainLabels.csv porque no es una imagen \n",
        "\n",
        "#Definimos las nuevas dimensiones de las imagenes \n",
        "\n",
        "img_filas, img_column = 200, 200\n",
        "\n",
        "#Creamos dos listas\n",
        "im_matriz = []\n",
        "im_Label = []\n",
        "\n",
        "for file in arch:\n",
        "    base = os.path.basename('train/' + file)\n",
        "    fileName = os.path.splitext(base)[0]\n",
        "    im_Label.append(trainLabels.loc[trainLabels.image==fileName, 'level'].values[0]) #Anadimos los nombre de cada archo y level a la lista im_Label\n",
        "    im = Image.open('train/' + file)\n",
        "    img = im.resize((img_filas,img_column))\n",
        "    gr = img.convert('L') #Convertimos las imagenes a monocromatico\n",
        "    im_matriz.append(np.array(gr).flatten()) #Anadimos cada imagen en la lista im_matriz (colapsando cada imagen(matriz) en unsa sola dimension)\n",
        "\n",
        "\n",
        "#Convertimos de lista a array\n",
        "\n",
        "im_matriz = np.asarray(im_matriz)\n",
        "im_Label = np.asarray(im_Label)\n",
        "\n",
        "#Se mezclara los arrays de un amanera consistente\n",
        "\n",
        "data,Label = shuffle(im_matriz,im_Label, random_state=2)\n",
        "train_data = [data,Label] #almacena los arrays en train_data en forma de lista\n",
        "\n",
        "#Preparamos las variables para el entrenamiento\n",
        "\n",
        "(X, y) = (train_data[0],train_data[1]) #Asignamos de la forma X=data y=label\n",
        "\n",
        "#Dividimos X, y para el entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
        "\n",
        "#Redimensionamos las imagenes nuevas\n",
        "X_train = X_train.reshape(X_train.shape[0], img_column, img_filas, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_column, img_filas, 1)\n",
        "\n",
        "#Convertimos las imagenes en el tipo de archivo float32 para poder realizar operaciones \n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train = X_train/255  \n",
        "X_test = X_test/255     #Debemos recordar que: \"Cada píxel de una imagen almacena la información de su tono o luminosidad, donde el tono negro es el valor 0 y el blanco el valor más alto (normalmente 255 en escala de grises), pero en formato binario\".\n",
        "\n",
        "#Trabajamos con los valores de y_train y_test\n",
        "\n",
        "clases = 5  #Definimos el numero de clases para la salida\n",
        "\n",
        "#Convertimos los valores de y_train y_test que son vectores a una matriz de clase binaria\n",
        "Y_train = np_utils.to_categorical(y_train, clases)\n",
        "Y_test = np_utils.to_categorical(y_test, clases)\n",
        "\n",
        "#Ahora se construira la red neuronal convolucional\n",
        "\n",
        "batch_size = 60  #definimos el numero de muestras que se propagaran en la red neural() \n",
        "epocas = 10  #Definimos el numero de epocas para el entrenamiento\n",
        "\n",
        "filtros = 32 #Definimos el numero de filtros \n",
        "nb_pool = 3     #Definimos el tamano de la matriz para reliazar el max pooling\n",
        "nb_conv = 4     #Tamano del kernel(nucleo) para convolucion\n",
        "\n",
        "\n",
        "clasificador = Sequential()\n",
        "clasificador.add(Convolution2D(filtros, kernel_size=(nb_conv, nb_conv), border_mode='valid', input_shape=(img_column, img_filas, 1), activation='relu'))\n",
        "clasificador.add(Convolution2D(filtros, kernel_size=(nb_conv, nb_conv), activation='relu'))\n",
        "clasificador.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
        "\n",
        "clasificador.add(Convolution2D(2*filtros, kernel_size=(nb_conv, nb_conv), activation='relu'))\n",
        "clasificador.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
        "\n",
        "#clasificador.add(Dropout(0.5)) #El Dropout se usa para ignorar algunas neuronas durante el entrenamiento\n",
        "\n",
        "clasificador.add(Flatten())\n",
        "clasificador.add(Dense(128))#Anade 128 neuronas\n",
        "clasificador.add(Activation('relu'))\n",
        "\n",
        "clasificador.add(Dense(256))\n",
        "clasificador.add(Activation('relu'))\n",
        "clasificador.add(Dropout(0.5))\n",
        "\n",
        "clasificador.add(Dense(clases)) #Anade en la salida el mismo numero de neuronas que de clases(osea los niveles de retinopatia)\n",
        "clasificador.add(Activation('softmax'))\n",
        "\n",
        "clasificador.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "#Se generan lotes de datos de imágenes de tensor con aumento de datos en tiempo real. Los datos se incluirán (en lotes). Estos se usaran para el entrenamiento.\n",
        "\n",
        "ValidadorDatGenerados = ImageDataGenerator()\n",
        "GeneradorDatEntr = ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1,rotation_range=15,zoom_range=0.1 ) #Editamos las imagenes un poco para aumentar el nuemro de datos\n",
        "\n",
        "#generamos los datos extras con el batch_size especificado anteriormente\n",
        "train_generator=GeneradorDatEntr.flow(X_train, Y_train, batch_size=batch_size) \n",
        "validation_generator=ValidadorDatGenerados.flow(X_test, Y_test,batch_size=batch_size)\n",
        "\n",
        "#Comenzamos el entrenamiento\n",
        "clasificador.fit_generator(train_generator, steps_per_epoch=int(len(X_train)/batch_size), epochs=epocas, validation_data=validation_generator, validation_steps=int(len(X_test)/batch_size))\n",
        "\n",
        "score = clasificador.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)\n",
        "\n",
        "\n",
        "target_dir = 'Introducir la ruta donde se guardara los archivos'\n",
        "if not os.path.exists(target_dir):\n",
        "  os.mkdir(target_dir)\n",
        "clasificador.save('modeloFinal.h5')\n",
        "clasificador.save_weights('pesosFinal.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "colab_type": "code",
        "id": "Gt5j3jKl6_Sm",
        "outputId": "1e056e47-8867-4536-d91d-fc9e7c414aeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.18784669 0.21716397 0.19344036 0.2246132  0.1769358 ]\n",
            "Prediccion:  RD Severo\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 11,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "from PIL import Image\n",
        "from keras.preprocessing import image\n",
        "\n",
        "img_filas, img_column = 200, 200\n",
        "modelo = 'modeloFinal.h5'\n",
        "pesos_modelo = 'pesosFinal.h5'\n",
        "clasificador = load_model(modelo)\n",
        "clasificador.load_weights(pesos_modelo)\n",
        "\n",
        "def predict(file):\n",
        "\n",
        "    img = image.load_img(file)\n",
        "    img = im.resize((img_filas,img_column))\n",
        "    img = img.convert('L')\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    data = img.astype('float32')\n",
        "    data = data/255\n",
        "\n",
        "    array = clasificador.predict(data)\n",
        "    result = array[0]\n",
        "    print(result)\n",
        "    answer = np.argmax(result)\n",
        "\n",
        "    if answer == 4:\n",
        "        print('Prediccion:  RD Proliferativa')\n",
        "    elif answer == 3:\n",
        "        print('Prediccion:  RD Severo')\n",
        "    elif answer == 2:\n",
        "        print('Prediccion:  RD Moderado')\n",
        "    elif answer == 1:\n",
        "        print('Prediccion:  RD Leve')\n",
        "    elif answer == 0:\n",
        "        print('Prediccion:  No Padece de RD')\n",
        "\n",
        "    return answer\n",
        "\n",
        "predict('Introducir la ruta del archivo de prueba')"
      ]
    }
  ]
}